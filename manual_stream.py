import cv2
import matplotlib.pyplot as plt
import easyocr
from ultralytics import YOLO
import os
import django
import time
import re
from pathlib import Path

# ğŸ›  Django setup
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "smarttrack.settings")
django.setup()

from parking.models import Vehicle, EntryExitLog
from django.utils import timezone

# ğŸ“¦ Load YOLOv8 model
model = YOLO("runs/detect/train3/weights/best.pt")

# ğŸ¥ Open camera
cap = None
for i in range(5):
    temp_cap = cv2.VideoCapture(i)
    ret, frame = temp_cap.read()
    if ret and frame is not None:
        print(f"âœ… Found working camera at index {i}")
        cap = temp_cap
        break
    temp_cap.release()

if cap is None:
    raise RuntimeError("âŒ No available camera found.")

# ğŸ§  OCR engine
reader = easyocr.Reader(["en"])

# ğŸ“‚ Create 'entries' folder if it doesn't exist
entries_folder = Path("entries")
entries_folder.mkdir(exist_ok=True)

# ğŸ“Š Matplotlib live view
plt.ion()
fig, ax = plt.subplots()

def clean_plate_text(text):
    """Clean OCR text to plate format."""
    text = re.sub(r'[^A-Z0-9]', '', text.upper())
    return text if 5 <= len(text) <= 12 else None

print("[ğŸ“¡] Stream started... Press SPACE to capture a car.")

snapshot_taken = False

while True:
    ret, frame = cap.read()
    if not ret or frame is None:
        print("âŒ Frame capture failed.")
        time.sleep(1)
        continue

    # ğŸ“º Live stream
    ax.clear()
    ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    ax.set_title("ğŸš— Press SPACE to capture vehicle")
    ax.axis("off")
    plt.pause(0.001)

    # ğŸ§  Wait for key press
    key = cv2.waitKey(1) & 0xFF

    if key == 32:  # SPACE key pressed
        print("ğŸ“¸ Snapshot captured!")
        snapshot_taken = True
    elif key == ord('q'):  # Press 'q' to quit manually
        print("ğŸ‘‹ Quitting stream manually...")
        break

    if snapshot_taken:
        # ğŸ“· Save full frame
        save_path = entries_folder / f"capture_{int(time.time())}.jpg"
        cv2.imwrite(str(save_path), frame)
        print(f"ğŸ’¾ Image saved to: {save_path}")

        # ğŸ” Run YOLO on captured frame
        results = model(frame)[0]

        plate_detected = False

        for box in results.boxes:
            if box.conf < 0.5:
                continue

            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
            cropped = frame[y1:y2, x1:x2]

            # ğŸ§  OCR on cropped plate
            ocr_result = reader.readtext(cropped)
            plate = clean_plate_text(ocr_result[0][1]) if ocr_result else None

            if plate:
                print(f"[âœ…] Plate Detected: {plate}")
                plate_detected = True

                # ğŸ“ Save to DB
                vehicle, _ = Vehicle.objects.get_or_create(license_plate=plate)
                EntryExitLog.objects.create(vehicle=vehicle, entry_time=timezone.now())

                # ğŸ– Annotate
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(
                    frame,
                    plate,
                    (x1, max(y1 - 10, 0)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.9,
                    (255, 0, 0),
                    2,
                )

                # ğŸ¯ Show result
                ax.clear()
                ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                ax.set_title(f"âœ… Captured: {plate}")
                ax.axis("off")
                plt.pause(2)

                break  # Only log 1 plate

        if not plate_detected:
            print("âŒ No plate detected in captured image.")

        print("ğŸ‘‹ Stream closed after capture.")
        break

# ğŸšª Clean exit
cap.release()
cv2.destroyAllWindows()
